{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis\\AppData\\Local\\Temp\\ipykernel_16860\\3712456616.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"car_price_model.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7894\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7894/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ‚úÖ Load dataset to extract feature names\n",
    "car_data = pd.read_csv(\"car_price_dataset.csv\")  # Ensure dataset is accessible\n",
    "car_data[\"Brand_model\"] = car_data[\"Brand\"] + \"_\" + car_data[\"Model\"]\n",
    "car_data = car_data.drop(columns=[\"Brand\", \"Model\"])\n",
    "\n",
    "# ‚úÖ Load preprocessing objects\n",
    "with open(\"fuel_encoder.pkl\", \"rb\") as f:\n",
    "    ordinal_fuel = pickle.load(f)\n",
    "\n",
    "with open(\"trasmission_encoder.pkl\", \"rb\") as f:\n",
    "    ordinal_transmission = pickle.load(f)\n",
    "\n",
    "with open(\"brand_encoder.pkl\", \"rb\") as f:\n",
    "    brand_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"Price_scaler.pkl\", \"rb\") as f:\n",
    "    Price_scaler = pickle.load(f)\n",
    "\n",
    "with open(\"Owner_Count_scaler.pkl\", \"rb\") as f:\n",
    "    Owner_count_scaler = pickle.load(f)\n",
    "\n",
    "with open(\"Mileage_scaler.pkl\", \"rb\") as f:\n",
    "    Mileage_scaler = pickle.load(f)\n",
    "\n",
    "# ‚úÖ Identify categorical & numerical columns\n",
    "categorical_features = [\"Fuel_Type\", \"Transmission\", \"Brand_model\"]\n",
    "numerical_features = [\"Year\", \"Engine_Size\", \"Mileage\", \"Doors\", \"Owner_Count\"]\n",
    "all_features = categorical_features + numerical_features\n",
    "\n",
    "# ‚úÖ Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ‚úÖ Load the trained model\n",
    "model = torch.load(\"car_price_model.pth\", map_location=device)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ‚úÖ Extract categorical options dynamically from dataset\n",
    "categorical_options = {\n",
    "    \"Fuel_Type\": [\"Electric\", \"Hybrid\", \"Diesel\", \"Petrol\"],\n",
    "    \"Transmission\": [\"Automatic\", \"Semi-Automatic\", \"Manual\"],\n",
    "    \"Brand_model\": list(car_data[\"Brand_model\"].unique())  # Get unique (Brand, Model) names\n",
    "}\n",
    "\n",
    "# ‚úÖ Initialize session state to store inputs\n",
    "session_state = {\n",
    "    \"step\": 0,\n",
    "    \"inputs\": {feature: None for feature in all_features}\n",
    "}\n",
    "\n",
    "# ‚úÖ Function to apply preprocessing before prediction\n",
    "def preprocess_input(inputs):\n",
    "    \"\"\"Apply the same preprocessing transformations as in training.\"\"\"\n",
    "    # Encode categorical variables\n",
    "    fuel_transformed = ordinal_fuel.transform([[inputs[\"Fuel_Type\"]]])[0][0]\n",
    "    transmission_transformed = ordinal_transmission.transform([[inputs[\"Transmission\"]]])[0][0]\n",
    "    brand_transformed = brand_encoder.transform([inputs[\"Brand_model\"]])[0]  # Encode brand\n",
    "\n",
    "    # Transform numerical features\n",
    "    mileage_transformed = np.log(inputs[\"Mileage\"])  # Apply log transformation\n",
    "    year_transformed = car_data[\"Year\"].max() - inputs[\"Year\"]  # Convert Year to Age\n",
    "\n",
    "    # Scale numerical values using the correct scalers\n",
    "    mileage_scaled = Mileage_scaler.transform([[mileage_transformed]])[0][0]\n",
    "    owner_count_scaled = Owner_count_scaler.transform([[inputs[\"Owner_Count\"]]])[0][0]\n",
    "\n",
    "    # Include Engine_Size and Doors\n",
    "    engine_size = inputs[\"Engine_Size\"]\n",
    "    doors = inputs[\"Doors\"]\n",
    "\n",
    "    # Combine processed features\n",
    "    processed_input = [\n",
    "        fuel_transformed, transmission_transformed, brand_transformed,\n",
    "        year_transformed, engine_size, mileage_scaled, doors, owner_count_scaled\n",
    "    ]\n",
    "\n",
    "    return torch.tensor([processed_input], dtype=torch.float32).to(device)\n",
    "\n",
    "# ‚úÖ Function to make predictions when all inputs are provided\n",
    "def predict_price():\n",
    "    if None in session_state[\"inputs\"].values():\n",
    "        return \"Waiting for all inputs...\"\n",
    "\n",
    "    # Preprocess input\n",
    "    processed_input = preprocess_input(session_state[\"inputs\"])\n",
    "\n",
    "    # Make a prediction\n",
    "    with torch.no_grad():\n",
    "        prediction_scaled = model(processed_input).cpu().numpy()[0][0]  # Extract scalar value\n",
    "\n",
    "    # Inverse scale price\n",
    "    prediction = Price_scaler.inverse_transform([[prediction_scaled]])[0][0]\n",
    "\n",
    "    return f\"Estimated Car Price: ${prediction:,.2f}\"\n",
    "\n",
    "# ‚úÖ Function to handle navigation between features\n",
    "def update_interface(value=None):\n",
    "    \"\"\"Store user input, move to next feature, and update UI.\"\"\"\n",
    "    if value is not None:  # Only store value if provided\n",
    "        current_feature = all_features[session_state[\"step\"]]\n",
    "        session_state[\"inputs\"][current_feature] = value\n",
    "        \n",
    "        # Move to next step if value was provided\n",
    "        if session_state[\"step\"] < len(all_features) - 1:\n",
    "            session_state[\"step\"] += 1\n",
    "\n",
    "    # Get current feature type\n",
    "    current_feature = all_features[session_state[\"step\"]]\n",
    "    is_categorical = current_feature in categorical_features\n",
    "\n",
    "    # Update visibility and values\n",
    "    dropdown_update = gr.update(\n",
    "        label=f\"Select {current_feature}\",\n",
    "        choices=categorical_options[current_feature] if is_categorical else [],\n",
    "        visible=is_categorical\n",
    "    )\n",
    "    \n",
    "    number_update = gr.update(\n",
    "        label=f\"Enter {current_feature}\",\n",
    "        visible=not is_categorical\n",
    "    )\n",
    "\n",
    "    # Show back button if not on first step\n",
    "    back_button_update = gr.update(visible=session_state[\"step\"] > 0)\n",
    "\n",
    "    prediction = predict_price()\n",
    "\n",
    "    return [dropdown_update, number_update, prediction, back_button_update]\n",
    "\n",
    "# ‚úÖ Function to handle next button for numeric inputs\n",
    "def handle_next_button(number_value):\n",
    "    \"\"\"Process numeric input when Next button is clicked.\"\"\"\n",
    "    current_feature = all_features[session_state[\"step\"]]\n",
    "    is_categorical = current_feature in categorical_features\n",
    "    \n",
    "    # Only process if we're on a numeric input\n",
    "    if not is_categorical and number_value is not None:\n",
    "        return update_interface(number_value)\n",
    "    \n",
    "    # Otherwise return the current state\n",
    "    return [\n",
    "        gr.update(),  # dropdown\n",
    "        gr.update(),  # number input\n",
    "        predict_price(),  # prediction\n",
    "        gr.update(visible=session_state[\"step\"] > 0)  # back button\n",
    "    ]\n",
    "\n",
    "# ‚úÖ Function to go back\n",
    "def go_back():\n",
    "    \"\"\"Move back to the previous feature.\"\"\"\n",
    "    if session_state[\"step\"] > 0:\n",
    "        session_state[\"step\"] -= 1\n",
    "        # Clear the input for the current step\n",
    "        current_feature = all_features[session_state[\"step\"]]\n",
    "        session_state[\"inputs\"][current_feature] = None\n",
    "    \n",
    "    return update_interface()\n",
    "\n",
    "# ‚úÖ Define Gradio Interface (Clean & Minimal UI)\n",
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"# üöó Car Price Estimator\")\n",
    "\n",
    "    with gr.Row():  # Input and Output in separate columns\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### Enter Vehicle Details\")\n",
    "\n",
    "            # ‚úÖ Create both a dropdown and a number input\n",
    "            dropdown_input = gr.Dropdown(label=\"Select Feature\", choices=[], interactive=True)\n",
    "            number_input = gr.Number(label=\"Enter Feature\", interactive=True)\n",
    "\n",
    "            with gr.Row():  # Small, non-intrusive buttons\n",
    "                back_button = gr.Button(\"‚¨ÖÔ∏è Back\", size=\"sm\", visible=False)\n",
    "                next_button = gr.Button(\"‚û°Ô∏è Next\", size=\"sm\")\n",
    "\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### Estimated Price\")\n",
    "            output_text = gr.Textbox(value=\"Waiting for all inputs...\", interactive=False)\n",
    "\n",
    "    # ‚úÖ Button Actions\n",
    "    next_button.click(\n",
    "        handle_next_button,\n",
    "        inputs=[number_input],\n",
    "        outputs=[dropdown_input, number_input, output_text, back_button]\n",
    "    )\n",
    "\n",
    "    dropdown_input.change(\n",
    "        update_interface,\n",
    "        inputs=[dropdown_input],\n",
    "        outputs=[dropdown_input, number_input, output_text, back_button]\n",
    "    )\n",
    "\n",
    "    number_input.submit(\n",
    "        update_interface,\n",
    "        inputs=[number_input],\n",
    "        outputs=[dropdown_input, number_input, output_text, back_button]\n",
    "    )\n",
    "\n",
    "    back_button.click(\n",
    "        go_back,\n",
    "        outputs=[dropdown_input, number_input, output_text, back_button]\n",
    "    )\n",
    "\n",
    "    # Initialize the interface\n",
    "    iface.load(\n",
    "        update_interface,\n",
    "        outputs=[dropdown_input, number_input, output_text, back_button]\n",
    "    )\n",
    "\n",
    "# ‚úÖ Launch the Gradio app\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Notebook successfully converted to Python script!\n"
     ]
    }
   ],
   "source": [
    "import nbconvert\n",
    "\n",
    "converter = nbconvert.ScriptExporter()\n",
    "body, _ = converter.from_filename(\"app.ipynb\")\n",
    "\n",
    "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(body)\n",
    "\n",
    "print(\"‚úÖ Notebook successfully converted to Python script!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
